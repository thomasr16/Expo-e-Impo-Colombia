{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61d5d4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Error: No se encuentra el archivo etl_tools.py en C:\\Users\\thoma\\Documentos\\Analisis de Datos\\Portafolio Proyectos\\Expo e Impo Colombia\\src\n"
     ]
    }
   ],
   "source": [
    "# Comandos m√°gicos para recargar cambios en tu script sin reiniciar el kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "# \"..\" significa subir un nivel (salir de notebooks) y entrar a scripts\n",
    "ruta_scripts = r'C:\\Users\\thoma\\Documentos\\Analisis de Datos\\Portafolio Proyectos\\Expo e Impo Colombia\\src'\n",
    "if ruta_scripts not in sys.path:\n",
    "    sys.path.append(ruta_scripts)\n",
    "\n",
    "# Ahora importamos tu funci√≥n\n",
    "try:\n",
    "    import etl_tools as etl\n",
    "    print(\"Librer√≠a etl_tools importada correctamente.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error: No se encuentra el archivo etl_tools.py en {ruta_scripts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---IMPORTACIONES ----- \n",
    "\n",
    "#Rutas de entrada\n",
    "ruta_zips_impo = os.path.join('..', 'Data', 'Impo')\n",
    "ruta_zips_expo = os.path.join('..', 'Data', 'Expo')\n",
    "\n",
    "# Rutas de salida \n",
    "lake_impo = os.path.join('..','Data', 'datalake_impo')\n",
    "lake_expo = os.path.join('..', 'Data', 'datalake_expo')\n",
    "\n",
    "#----Columnas que usaremos de importaciones------\n",
    "cols_impo = ['FECH', 'PAISGEN' , 'VAFODO', 'PBK', 'ADUA', 'NABAN', 'REGIMEN']\n",
    "txt_impo  = ['FECH', 'PAISGEN', 'ADUA', 'NABAN', 'REGIMEN']\n",
    "num_impo  = ['VAFODO', 'PBK']\n",
    "\n",
    "#----Columnas que usaremos de exportaciones------\n",
    "cols_expo = ['FECH', 'PAIS' , 'FOBDOL', 'PBK', 'ADUA', 'POSAR', 'MODAD'] \n",
    "txt_expo  = ['FECH', 'PAIS' , 'ADUA', 'POSAR' , 'MODAD']\n",
    "num_expo  = ['FOBDOL', 'PBK']\n",
    "\n",
    "\n",
    "print(\"Configuraci√≥n lista.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dcc6be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INICIANDO CONSTRUCCI√ìN DE DATA LAKES\n",
      "========================================\n",
      "\n",
      "üì¶ Procesando Importaciones...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'etl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 1. Procesar IMPORTACIONES\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müì¶ Procesando Importaciones...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43metl\u001b[49m\u001b[38;5;241m.\u001b[39mzips_a_parquet(\n\u001b[0;32m      7\u001b[0m     ruta_origen\u001b[38;5;241m=\u001b[39mruta_zips_impo,\n\u001b[0;32m      8\u001b[0m     ruta_destino\u001b[38;5;241m=\u001b[39mlake_impo,\n\u001b[0;32m      9\u001b[0m     columnas_necesarias\u001b[38;5;241m=\u001b[39mcols_impo,\n\u001b[0;32m     10\u001b[0m     cols_texto\u001b[38;5;241m=\u001b[39mtxt_impo,\n\u001b[0;32m     11\u001b[0m     cols_numero\u001b[38;5;241m=\u001b[39mnum_impo\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 2. Procesar EXPORTACIONES\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'etl' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ INICIANDO CONSTRUCCI√ìN DE DATA LAKES\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# 1. Procesar IMPORTACIONES\n",
    "print(f\"\\nüì¶ Procesando Importaciones...\")\n",
    "etl.zips_a_parquet(\n",
    "    ruta_origen=ruta_zips_impo,\n",
    "    ruta_destino=lake_impo,\n",
    "    columnas_necesarias=cols_impo,\n",
    "    cols_texto=txt_impo,\n",
    "    cols_numero=num_impo\n",
    ")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 2. Procesar EXPORTACIONES\n",
    "print(f\"\\nüì¶ Procesando Exportaciones...\")\n",
    "\n",
    "try:\n",
    "    etl.zips_a_parquet(\n",
    "        ruta_origen=ruta_zips_expo,\n",
    "        ruta_destino=lake_expo,\n",
    "        columnas_necesarias=cols_expo,\n",
    "        cols_texto=txt_expo,\n",
    "        cols_numero=num_expo\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error en Exportaciones: {e}\")\n",
    "    print(\"Consejo: Abre un archivo .dta de expo individualmente para verificar los nombres exactos de las columnas.\")\n",
    "\n",
    "print(\"\\n‚ú® ¬°PROCESO FINALIZADO!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62060a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificaci√≥n r√°pida\n",
    "print(\"--- Auditor√≠a de Datos ---\")\n",
    "\n",
    "try:\n",
    "    # Chequeo Impo\n",
    "    df_impo = pl.scan_parquet(os.path.join(lake_impo, \"*.parquet\"))\n",
    "    conteo_impo = df_impo.select(pl.len()).collect().item()\n",
    "    print(f\"‚úÖ Data Lake Importaciones: {conteo_impo:,.0f} registros accesibles.\")\n",
    "    \n",
    "    # Chequeo Expo\n",
    "    df_expo = pl.scan_parquet(os.path.join(lake_expo, \"*.parquet\"))\n",
    "    conteo_expo = df_expo.select(pl.len()).collect().item()\n",
    "    print(f\"‚úÖ Data Lake Exportaciones: {conteo_expo:,.0f} registros accesibles.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Algo sali√≥ mal al leer los parquets: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
